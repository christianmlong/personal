"""
write_shopfloor_monitor_data_tests.py

Script to automatically generate a test for each data access object in
shopfloor_monitor_data, to test the sql generation.
"""

# Nose should not run this when it is runing tests.
__test__ = False

#import pprint, os.path

import sys, os

from CML_Pickpack.pickpack_modules import pickpack_constants
from CML_Pickpack.pickpack_modules import shopfloor_monitor_data

base_path = os.path.abspath(os.path.dirname(sys.argv[0]))

FILE_PATH = os.path.join(base_path, 'test_shopfloor_monitor_data.py')

HEADER = '''# pylint: disable=too-many-lines,too-many-public-methods,line-too-long,missing-docstring
"""
Tests for the sql generation objects of the shopfloor_monitor_data module.

DO NOT EDIT THIS FILE
IT IS AUTOMATICALLY GENERATED
BY write_shopfloor_monitor_data_tests.py



"""

from nose import tools
from nose.plugins.attrib import attr

import pyodbc, sqlparse

from CML_Pickpack.pickpack_modules import pickpack_constants
from CML_Pickpack.pickpack_modules import shopfloor_monitor_data

if pickpack_constants.SHOW_FULL_DIFF:
    # Force Nose to output the full diff
    from unittest import TestCase
    TestCase.maxDiff = None

APLUS_CONNECTION = None

def setup_module():
    """
    Module-level setup code for the tests
    """
    global APLUS_CONNECTION                             # pylint: disable=global-statement
    APLUS_CONNECTION = pyodbc.connect('DSN=Test;UID=NONE;PWD=NONE;') # pylint: disable=no-member

def teardown_module():
    """
    Module-level teardown code for the tests
    """
    APLUS_CONNECTION.close()


class TestShopfloorMonitorDataSQL(object):

    WORKSTATION_DICT = {
        "wcc"       : pickpack_constants.CONSUMABLES_SCALE,
        "parts"     : pickpack_constants.SERVICE_PARTS_SCALE,
        "both"      : pickpack_constants.BOTH_SCALE,
        "all"       : pickpack_constants.ALL_SCALES,
    }

    def __init__(self):
        pass

    def validate(self,
                 data_provider_object,
                 workstation,
                 expected_sql,
                ):
        workstation_code = self.WORKSTATION_DICT[workstation]
        actual_sql = data_provider_object.build_sql(workstation_code)
        actual_sql_tree = sqlparse.parse(actual_sql)[0]
        expected_sql_tree = sqlparse.parse(expected_sql)[0]
        actual_sql_clean = unicode(actual_sql_tree)
        expected_sql_clean = unicode(expected_sql_tree)
        #import pprint
        #print "++++++++++++++++++++++++++++++++++++++++++"
        #print pprint.pformat(actual_sql_clean)
        #print "------------------------------------------"
        #print pprint.pformat(expected_sql_clean)
        #print "++++++++++++++++++++++++++++++++++++++++++"
        tools.assert_equal(actual_sql_clean, expected_sql_clean)

        cur = APLUS_CONNECTION.cursor()
        cur.execute(actual_sql)
        result = cur.fetchall()
        cur.close()

        print
        if result is None:
            print "None"
        elif len(result) == 0:
            print "No rows"
        elif len(result) == 1:
            print "1 row"
            print result[0]
        elif len(result) <= 10:
            print "%s rows" % len(result)
            for row in result:
                print row
        else:
            print "10 rows of %s" % len(result)
            for row in result[:10]:
                print row

'''


TEST_TEMPLATE = '''
    @attr('slow')
    def test_{object_name}_{workstation}(self):
        expected_sql = """{expected_sql}"""
        self.validate(shopfloor_monitor_data.{object_name},
                      '{workstation}',
                      expected_sql,
                      )

'''


def main():
    """
    Main function
    """
    write_tests()

def write_tests():
    """
    Call the given object's build_sql() and get a response. Create a test based
    on that response. Write that test to the file.
    """

    objects = (
        ('today_sure_ordinary_summary_provider'                 ,  shopfloor_monitor_data.today_sure_ordinary_summary_provider),
        ('today_sure_ordinary_detail_data_provider'             ,  shopfloor_monitor_data.today_sure_ordinary_detail_data_provider),
        ('today_sure_backorder_summary_provider'                ,  shopfloor_monitor_data.today_sure_backorder_summary_provider),
        ('today_sure_backorder_detail_data_provider'            ,  shopfloor_monitor_data.today_sure_backorder_detail_data_provider),
        ('today_sure_last_print_data_provider'                  ,  shopfloor_monitor_data.today_sure_last_print_data_provider),
        ('signature_service_ordinary_summary_provider'          ,  shopfloor_monitor_data.signature_service_ordinary_summary_provider),
        ('signature_service_ordinary_detail_data_provider'      ,  shopfloor_monitor_data.signature_service_ordinary_detail_data_provider),
        ('signature_service_backorder_summary_provider'         ,  shopfloor_monitor_data.signature_service_backorder_summary_provider),
        ('signature_service_backorder_detail_data_provider'     ,  shopfloor_monitor_data.signature_service_backorder_detail_data_provider),
        ('signature_service_last_print_data_provider'           ,  shopfloor_monitor_data.signature_service_last_print_data_provider),
        ('service_files_ordinary_summary_provider'              ,  shopfloor_monitor_data.service_files_ordinary_summary_provider),
        ('service_files_ordinary_detail_data_provider'          ,  shopfloor_monitor_data.service_files_ordinary_detail_data_provider),
        ('service_files_backorder_summary_provider'             ,  shopfloor_monitor_data.service_files_backorder_summary_provider),
        ('service_files_backorder_detail_data_provider'         ,  shopfloor_monitor_data.service_files_backorder_detail_data_provider),
        ('service_files_last_print_data_provider'               ,  shopfloor_monitor_data.service_files_last_print_data_provider),
        ('normal_ordinary_summary_provider'                     ,  shopfloor_monitor_data.normal_ordinary_summary_provider),
        ('normal_ordinary_detail_data_provider'                 ,  shopfloor_monitor_data.normal_ordinary_detail_data_provider),
        ('normal_backorder_summary_provider'                    ,  shopfloor_monitor_data.normal_backorder_summary_provider),
        ('normal_backorder_detail_data_provider'                ,  shopfloor_monitor_data.normal_backorder_detail_data_provider),
        ('normal_last_print_data_provider'                      ,  shopfloor_monitor_data.normal_last_print_data_provider),
    )
    shipping_stations = {
        "wcc"       : pickpack_constants.CONSUMABLES_SCALE,
        "parts"     : pickpack_constants.SERVICE_PARTS_SCALE,
        "both"      : pickpack_constants.BOTH_SCALE,
        "all"       : pickpack_constants.ALL_SCALES,
    }
    with open(FILE_PATH, 'w') as file_object:
        file_object.write(HEADER)
        for obj_name, obj in objects:
            for shipping_station_name, shipping_station_code in shipping_stations.items():
                write_test(file_object,
                           obj_name,
                           obj,
                           shipping_station_name,
                           shipping_station_code,
                          )










def write_test(file_object,
               data_provider_object_name,
               data_provider_object,
               shipping_station_name,
               shipping_station_code,
              ):
    """
    Generate the code for a test, based on a template. Write the test out to the
    file.
    """

    expected_sql = data_provider_object.build_sql(shipping_station_code)

    output = TEST_TEMPLATE.format(object_name = data_provider_object_name,
                                  workstation = shipping_station_name,
                                  expected_sql = expected_sql,
                                 )

    file_object.write(output)



if __name__ == '__main__':
    main()
